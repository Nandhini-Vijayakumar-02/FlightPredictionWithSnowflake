{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "language": "python",
    "name": "cell1",
    "collapsed": false,
    "resultHeight": 0
   },
   "source": "# Import python packages\nimport streamlit as st\nimport pandas as pd\n\n# We can also use Snowpark for our analyses!\nfrom snowflake.snowpark.context import get_active_session\nsession = get_active_session()\n",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "8d50cbf4-0c8d-4950-86cb-114990437ac9",
   "metadata": {
    "language": "python",
    "name": "cell2",
    "collapsed": false,
    "resultHeight": 239
   },
   "source": "query = \"SELECT * FROM AIRLINE_ENRICHED\"\nflightsinfo2 = session.sql(query).to_pandas()\n\n# Use pandas describe method for descriptive statistics\nsummary = flightsinfo2.describe()\n\n# Display the summary statistics\nprint(summary)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "c695373e-ac74-4b62-a1f1-08206cbd5c81",
   "metadata": {
    "language": "python",
    "name": "cell3",
    "collapsed": false,
    "resultHeight": 0
   },
   "source": "data_vizual = flightsinfo2[['AIRLINE', 'AIRLINE_NAME', 'ORG_AIRPORT_NAME', 'ORGIN_CITY',\n'DEST_AIRPORT_NAME', 'DESTINATION_CITY', 'ORIGIN_AIRPORT',\n'DESTINATION_AIRPORT', 'DISTANCE', 'Actual_Departure', 'DATE', 'WEEK',\n'Scheduled_Departure', 'DEPARTURE_DELAY', 'Actual_Arrival',\n'Scheduled_Arrival', 'ARRIVAL_DELAY', 'SCHEDULED_TIME', 'ELAPSED_TIME',\n'AIR_TIME', 'TAXI_IN', 'TAXI_OUT', 'WHEELS_OFF', 'SCHEDULED_DEPARTURE',\n'DEPARTURE_TIME', 'TIME_OF_DAY']]",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "102804ff-ce3f-41bf-ac47-f3154de8ea8c",
   "metadata": {
    "language": "python",
    "name": "cell4",
    "collapsed": false,
    "resultHeight": 0
   },
   "outputs": [],
   "source": "Flights = data_vizual.copy()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "70171555-2b3e-45ba-a3c8-02b2fcbd836d",
   "metadata": {
    "language": "python",
    "name": "cell5",
    "collapsed": false,
    "resultHeight": 0
   },
   "outputs": [],
   "source": "# Removing columns that are not needed for prediction\nFlights1 = Flights.drop([\n    'AIRLINE_NAME', \n    'ORG_AIRPORT_NAME', \n    'ORGIN_CITY',\n    'DEST_AIRPORT_NAME', \n    'DESTINATION_CITY', \n    'DISTANCE', \n    'Actual_Departure', \n    'Scheduled_Departure', \n    'Actual_Arrival',\n    'Scheduled_Arrival', \n    'SCHEDULED_TIME', \n    'ELAPSED_TIME',  \n    'AIR_TIME', 'TIME_OF_DAY'\n], axis=1)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b1a321e9-ca47-4021-b1ef-d1bbf88261d9",
   "metadata": {
    "language": "python",
    "name": "cell6",
    "collapsed": false,
    "resultHeight": 0
   },
   "outputs": [],
   "source": "import numpy as np\nFlights1['IS_DELAYED'] = np.where(Flights1['ARRIVAL_DELAY']<=0, 0,1)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ca054e8b-d234-4f93-bf65-387f157fc772",
   "metadata": {
    "language": "python",
    "name": "cell7",
    "collapsed": false,
    "resultHeight": 439
   },
   "outputs": [],
   "source": "Flights1.columns",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "bb2cfce3-c765-4a3a-9f17-89a7cbb58f86",
   "metadata": {
    "language": "python",
    "name": "cell8",
    "collapsed": false,
    "resultHeight": 156
   },
   "outputs": [],
   "source": "import joblib\nfrom sklearn.preprocessing import LabelEncoder\n\n# Columns to encode\ncolumns_to_encode = ['AIRLINE', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT', 'WEEK']\n\n# Dictionary to store the LabelEncoders and mappings\nlabel_encoders = {}\nmappings = {}\n\n# Apply LabelEncoder to selective columns\nfor column in columns_to_encode:\n    # Initialize a LabelEncoder for the column\n    encoder = LabelEncoder()\n    # Fit and transform the column in the dataset\n    Flights1[column] = encoder.fit_transform(Flights1[column])\n    # Store the LabelEncoder instance in the dictionary\n    label_encoders[column] = encoder\n    # Store the mapping (class to label) in the mappings dictionary\n    mappings[column] = dict(zip(encoder.classes_, encoder.transform(encoder.classes_)))\n\n# Display the mappings\nprint(\"\\nMappings:\")\nfor column, mapping in mappings.items():\n    print(f\"{column}_mapping: {mapping}\\n\")\nprint(\"-------------------------------------\")",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b1032c34-9018-4f7a-8bb9-84c8a0a06064",
   "metadata": {
    "language": "python",
    "name": "cell9",
    "collapsed": false,
    "resultHeight": 105
   },
   "outputs": [],
   "source": "import joblib\njoblib.dump(label_encoders, 'label_encoder_complete.joblib')",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "03febcf2-3e05-4f47-888d-91e0b9274fed",
   "metadata": {
    "language": "python",
    "name": "cell10",
    "collapsed": false,
    "resultHeight": 278
   },
   "outputs": [],
   "source": "X = Flights1.drop(['ARRIVAL_DELAY','IS_DELAYED','DATE'],axis = 1)\nX.shape\ny = Flights1['IS_DELAYED']\ny.head()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "727b5c7e-d730-47d3-966a-817c748813f2",
   "metadata": {
    "language": "python",
    "name": "cell11",
    "collapsed": false,
    "resultHeight": 0
   },
   "outputs": [],
   "source": "from sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state = 2)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c7c164dc-72b5-4239-87cc-3093c3970819",
   "metadata": {
    "language": "python",
    "name": "cell12",
    "collapsed": false,
    "resultHeight": 147
   },
   "outputs": [],
   "source": "y_train.value_counts()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6ecadea4-0ffe-48bf-b4b9-86f1d6e61611",
   "metadata": {
    "language": "python",
    "name": "cell13",
    "collapsed": false,
    "resultHeight": 0
   },
   "outputs": [],
   "source": "from imblearn.over_sampling import SMOTE\nsmt = SMOTE()\nX_train, y_train = smt.fit_resample(X_train, y_train)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4373c4a2-cbc9-4276-820e-b02e9c5d94e1",
   "metadata": {
    "language": "python",
    "name": "cell14",
    "collapsed": false,
    "resultHeight": 147
   },
   "outputs": [],
   "source": "import pandas as pd\npd.Series(y_train).value_counts()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "0b709ebc-4120-45e1-b751-3a12aa240077",
   "metadata": {
    "language": "python",
    "name": "cell15",
    "collapsed": false,
    "resultHeight": 0
   },
   "outputs": [],
   "source": "#Applying Standard Scalar for classification\nsc1=StandardScaler()\nX_train_sc=sc1.fit_transform(X_train)\nX_test_sc=sc1.transform(X_test)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b1e3a2d2-2935-40dc-b94f-a5cf433652b9",
   "metadata": {
    "language": "sql",
    "name": "cell16",
    "collapsed": false,
    "resultHeight": 0
   },
   "outputs": [],
   "source": "session.write_pandas(\n    Flights1, \n    \"FLIGHTDELAY_MODEL_DATA\", \n    auto_create_table=True)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ed3b06e1-2f35-415f-9850-ee13d035f174",
   "metadata": {
    "language": "sql",
    "name": "cell18",
    "collapsed": false,
    "resultHeight": 511
   },
   "outputs": [],
   "source": "SELECT * FROM FLIGHTDELAY_MODEL_DATA",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b92edf73-fc65-43c4-b382-0f0e22f30616",
   "metadata": {
    "language": "sql",
    "name": "cell19",
    "collapsed": false,
    "resultHeight": 112
   },
   "outputs": [],
   "source": "ALTER TABLE FLIGHTDELAY_MODEL_DATA ADD COLUMN converted_date TIMESTAMP_NTZ;\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ccfeb43e-6d4e-4b5a-bce8-8f2ee309abdc",
   "metadata": {
    "language": "sql",
    "name": "cell38",
    "resultHeight": 111
   },
   "outputs": [],
   "source": "UPDATE FLIGHTDELAY_MODEL_DATA\nSET converted_date = TO_TIMESTAMP_NTZ(date / 1e9);",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "51d01abb-bf3c-4c69-84c8-b0e9e8a9084d",
   "metadata": {
    "language": "python",
    "name": "cell17",
    "resultHeight": 0
   },
   "outputs": [],
   "source": "",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "66c9dbfc-6fa2-4dcc-a095-c551b65fcc4c",
   "metadata": {
    "language": "sql",
    "name": "cell21",
    "collapsed": false,
    "resultHeight": 112
   },
   "outputs": [],
   "source": "ALTER TABLE FLIGHTDELAY_MODEL_DATA DROP COLUMN DATE;\nALTER TABLE FLIGHTDELAY_MODEL_DATA RENAME COLUMN converted_date TO DATE;\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c77aedf0-77b0-4f0e-a97b-2885eba9ce9e",
   "metadata": {
    "language": "python",
    "name": "cell22",
    "collapsed": false,
    "resultHeight": 54
   },
   "outputs": [],
   "source": "from sklearn.tree import DecisionTreeClassifier\n# Initialize the DecisionTreeClassifier\nclassifierDT = DecisionTreeClassifier(criterion = 'entropy', random_state = 5)\n# Fit the classifier on the training data\nclassifierDT.fit(X_train_sc, y_train)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "06a14dda-d7b8-4980-8b0f-36506f7079f8",
   "metadata": {
    "language": "python",
    "name": "cell23",
    "collapsed": false,
    "resultHeight": 105
   },
   "outputs": [],
   "source": "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n# Predicting the Test set results\ny_pred_DT = classifierDT.predict(X_test_sc)\n# Making the Confusion Matrix\ncm = confusion_matrix(y_test, y_pred_DT)\nprint(f\"Confusion Matrix :\\n {cm}\")\n#Calculating the accuracy\nscore_DT = classifierDT.score(X_test_sc,y_test)\nprint(f\"Accuracy : {score_DT}\")",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6c114211-6462-4321-b4ed-40c46d76356c",
   "metadata": {
    "language": "python",
    "name": "cell24",
    "collapsed": false,
    "resultHeight": 83
   },
   "outputs": [],
   "source": "# Calculating F1 score,Precision,Recall of model\nF1_score_DT = f1_score(y_test, y_pred_DT, average=\"macro\")\nPrecision_DT = precision_score(y_test, y_pred_DT, average=\"macro\")\nRecall_DT = recall_score(y_test, y_pred_DT, average=\"macro\")\nprint(\"F1 score :\",F1_score_DT)\nprint(\"Precision Score :\" , Precision_DT)\nprint(\"Recall Score :\" , Recall_DT)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "23d76649-9ac1-4c8f-a478-d3534e99e347",
   "metadata": {
    "language": "python",
    "name": "cell25",
    "collapsed": false,
    "resultHeight": 41
   },
   "outputs": [],
   "source": "from sklearn.metrics import ConfusionMatrixDisplay\nimport matplotlib.pyplot as plt\nfrom matplotlib.ticker import FuncFormatter\n# Function to format tick labels in decimal notation\ndef format_func(value, tick_number):\n    return f'{int(value):,}'\n# Assuming `cm` is your confusion matrix\n# Set display labels to your desired labels\nlabels = ['Not Delayed', 'Delayed']\n# Create a ConfusionMatrixDisplay object\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n# Plot the confusion matrix\ndisp.plot(cmap=plt.cm.Greens, values_format='d')\n# Set the title of the plot\nplt.title('Confusion Matrix')\n# Apply custom formatting to both x and y axis tick labels\nplt.gca().xaxis.set_major_formatter(FuncFormatter(format_func))\nplt.gca().yaxis.set_major_formatter(FuncFormatter(format_func))\n# Manually set the tick labels\nplt.gca().set_xticks([0, 1])\nplt.gca().set_xticklabels(labels)\nplt.gca().set_yticks([0, 1])\nplt.gca().set_yticklabels(labels)\n# Show the plot\nplt.show()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7ff3b622-3286-48a0-8e1c-ac295f78a5bf",
   "metadata": {
    "language": "python",
    "name": "cell26",
    "collapsed": false,
    "resultHeight": 54
   },
   "outputs": [],
   "source": "from sklearn.neighbors import KNeighborsClassifier\n# Initialize the KNeighborsClassifier\nclassifier_Knn = KNeighborsClassifier(\nn_neighbors=5,\nalgorithm='auto', \nleaf_size=40, # Larger leaf size may speed up the training time\nmetric='euclidean',\nn_jobs=-1 # Use all available cores for parallel processing\n)\n# Fit the classifier on the training data\nclassifier_Knn.fit(X_train_sc,y_train)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c511af05-9783-47e0-804a-43cec51d792e",
   "metadata": {
    "language": "python",
    "name": "cell27",
    "collapsed": false,
    "resultHeight": 105
   },
   "outputs": [],
   "source": "# Predicting the Test set results\ny_pred_knn=classifier_Knn.predict(X_test_sc)\nfrom sklearn.metrics import confusion_matrix\n# Making the Confusion Matrix\ncm = confusion_matrix(y_test, y_pred_knn)\nprint(f\"Confusion Matrix :\\n {cm}\")\n#Calculating the accuracy\nscore_knn = classifier_Knn.score(X_test_sc,y_test)\nprint(f\"Accuracy : {score_knn}\")",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4b0c9d8e-3f49-4db3-adff-17eeb95b274f",
   "metadata": {
    "language": "python",
    "name": "cell28",
    "collapsed": false,
    "resultHeight": 83
   },
   "outputs": [],
   "source": "# Calculating F1 score,Precision,Recall of model\nF1_score_knn = f1_score(y_test, y_pred_knn, average=\"macro\")\nPrecision_knn = precision_score(y_test, y_pred_knn, average=\"macro\")\nRecall_knn = recall_score(y_test, y_pred_knn, average=\"macro\")\nprint(\"F1 score :\",F1_score_knn)\nprint(\"Precision Score :\",Precision_knn)\nprint(\"Recall Score :\",Recall_knn)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3c765f98-2ab0-47f6-a446-65621a87b437",
   "metadata": {
    "language": "python",
    "name": "cell29",
    "collapsed": false,
    "resultHeight": 41
   },
   "outputs": [],
   "source": "# Function to format tick labels in decimal notation\ndef format_func(value, tick_number):\n    return f'{int(value):,}'\n# Assuming `cm` is your confusion matrix\n# Set display labels to your desired labels\nlabels = ['Not Delayed', 'Delayed']\n# Create a ConfusionMatrixDisplay object\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n# Plot the confusion matrix\ndisp.plot(cmap=plt.cm.Greens, values_format='d')\n# Set the title of the plot\nplt.title('Confusion Matrix')\n# Apply custom formatting to both x and y axis tick labels\nplt.gca().xaxis.set_major_formatter(FuncFormatter(format_func))\nplt.gca().yaxis.set_major_formatter(FuncFormatter(format_func))\n# Manually set the tick labels\nplt.gca().set_xticks([0, 1])\nplt.gca().set_xticklabels(labels)\nplt.gca().set_yticks([0, 1])\nplt.gca().set_yticklabels(labels)\n# Show the plot\nplt.show()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "0e5fc72c-a6f5-41e3-bc98-bc90c35f3d6c",
   "metadata": {
    "language": "python",
    "name": "cell30",
    "collapsed": false,
    "resultHeight": 54
   },
   "outputs": [],
   "source": "from sklearn.linear_model import LogisticRegression\nclassifier_log = LogisticRegression(random_state = 0)\nclassifier_log.fit(X_train_sc, y_train)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4107bd17-fe7b-48c2-b828-659f833ccaef",
   "metadata": {
    "language": "python",
    "name": "cell31",
    "collapsed": false,
    "resultHeight": 105
   },
   "outputs": [],
   "source": "y_pred_log = classifier_log.predict(X_test_sc)\ncm = confusion_matrix(y_test, y_pred_log)\nprint(f\"Confusion Matrix :\\n {cm}\")\n#Calculating the accuracy\nscore_log = classifier_log.score(X_test_sc,y_test)\nprint(f\"Accuracy : {score_log}\")",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "cbb8862d-0e03-429c-9044-e948a6fb7f4e",
   "metadata": {
    "language": "python",
    "name": "cell32",
    "collapsed": false,
    "resultHeight": 83
   },
   "outputs": [],
   "source": "F1_score_log = f1_score(y_test, y_pred_log, average=\"macro\")\nPrecision_log = precision_score(y_test, y_pred_log, average=\"macro\")\nRecall_log = recall_score(y_test, y_pred_log, average=\"macro\")\nprint(\"F1 score :\",F1_score_log)\nprint(\"Precision Score :\",Precision_log)\nprint(\"Recall Score :\",Recall_log)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "47aa0c74-2885-4572-91cd-4c21efbc0992",
   "metadata": {
    "language": "python",
    "name": "cell33",
    "collapsed": false,
    "resultHeight": 41
   },
   "outputs": [],
   "source": "# Function to format tick labels in decimal notation\ndef format_func(value, tick_number):\n    return f'{int(value):,}'\n# Assuming `cm` is your confusion matrix\n# Set display labels to your desired labels\nlabels = ['Not Delayed', 'Delayed']\n# Create a ConfusionMatrixDisplay object\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n# Plot the confusion matrix\ndisp.plot(cmap=plt.cm.Greens, values_format='d')\n# Set the title of the plot\nplt.title('Confusion Matrix')\n# Apply custom formatting to both x and y axis tick labels\nplt.gca().xaxis.set_major_formatter(FuncFormatter(format_func))\nplt.gca().yaxis.set_major_formatter(FuncFormatter(format_func))\n# Manually set the tick labels\nplt.gca().set_xticks([0, 1])\nplt.gca().set_xticklabels(labels)\nplt.gca().set_yticks([0, 1])\nplt.gca().set_yticklabels(labels)\n# Show the plot\nplt.show()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8c9bbe3b-8fae-4133-a8e7-a6ed18a0dd43",
   "metadata": {
    "language": "python",
    "name": "cell34",
    "collapsed": false,
    "resultHeight": 54
   },
   "outputs": [],
   "source": "from sklearn.ensemble import RandomForestClassifier\n# Initialize the RandomForestClassifier\nclassifier_RF = RandomForestClassifier(\nrandom_state=0, # Seed for the random number generator to ensure reproducibility\nn_jobs=-1, # Use all available cores for parallel processing\nn_estimators=100, # Number of trees in the forest; fewer trees reduce model size\nmax_depth=10 # Maximum depth of each tree; shallower trees are smaller\n)\n# Fit the classifier on the training data\nclassifier_RF.fit(X_train_sc, y_train)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5124f846-fb5b-4de8-aa47-e988155409dd",
   "metadata": {
    "language": "python",
    "name": "cell35",
    "collapsed": false,
    "resultHeight": 105
   },
   "outputs": [],
   "source": "# Predicting the Test set results\ny_pred_RF = classifier_RF.predict(X_test_sc)\n# Making the Confusion Matrix\ncm = confusion_matrix(y_test, y_pred_RF)\nprint(f\"Confusion Matrix :\\n {cm}\")\n#Calculating the accuracy\nscore_RF = classifierDT.score(X_test_sc,y_test)\nprint(f\"Accuracy : {score_RF}\")",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "bad744a1-1375-4a96-8382-eddef2d50f87",
   "metadata": {
    "language": "python",
    "name": "cell36",
    "collapsed": false,
    "resultHeight": 83
   },
   "outputs": [],
   "source": "# Calculating F1 score,Precision,Recall of model\nF1_score_RF = f1_score(y_test, y_pred_RF, average=\"macro\")\nPrecision_RF = precision_score(y_test, y_pred_RF, average=\"macro\")\nRecall_RF = recall_score(y_test, y_pred_RF, average=\"macro\")\nprint(\"F1 score :\",F1_score_RF)\nprint(\"Precision Score :\",Precision_RF)\nprint(\"Recall Score :\",Recall_RF)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "67421054-d8ca-49ce-b54c-0e7ec39b18ca",
   "metadata": {
    "language": "python",
    "name": "cell37",
    "collapsed": false,
    "resultHeight": 41
   },
   "outputs": [],
   "source": "# Function to format tick labels in decimal notation\ndef format_func(value, tick_number):\n    return f'{int(value):,}'\n# Assuming `cm` is your confusion matrix\n# Set display labels to your desired labels\nlabels = ['Not Delayed', 'Delayed']\n# Create a ConfusionMatrixDisplay object\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n# Plot the confusion matrix\ndisp.plot(cmap=plt.cm.Greens, values_format='d')\n# Set the title of the plot\nplt.title('Confusion Matrix')\n# Apply custom formatting to both x and y axis tick labels\nplt.gca().xaxis.set_major_formatter(FuncFormatter(format_func))\nplt.gca().yaxis.set_major_formatter(FuncFormatter(format_func))\n# Manually set the tick labels\nplt.gca().set_xticks([0, 1])\nplt.gca().set_xticklabels(labels)\nplt.gca().set_yticks([0, 1])\nplt.gca().set_yticklabels(labels)\n# Show the plot\nplt.show()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8dc11706-9cf2-43ea-872c-46000b813544",
   "metadata": {
    "language": "python",
    "name": "cell40",
    "collapsed": false,
    "resultHeight": 0
   },
   "outputs": [],
   "source": "# Define the metrics Table of each Classification model for comparision\ncl_metrics = {\n'Accuracy': [score_DT,score_knn,score_log,score_RF],\n'F1-Score': [F1_score_DT,F1_score_knn,F1_score_log,F1_score_RF],\n'Precision': [Precision_DT,Precision_knn,Precision_log,Precision_RF],\n'Recall': [Recall_DT,Recall_knn,Recall_log,Recall_RF]\n}\n# Create a DataFrame from the metrics with models as the index\ncl_metrics_df = pd.DataFrame(cl_metrics, \n                             index=['DecisionTree', 'K-Nearest Neighbor', 'LogisticRegression','RandomForcl_metrics_df'])",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6f5d9d51-c12f-4ce9-9f20-82884d3d0d57",
   "metadata": {
    "language": "python",
    "name": "cell39"
   },
   "outputs": [],
   "source": "joblib.dump(classifier_log, 'logistic_regression_model.joblib')",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2269b5ed-75c9-41a9-bf3c-1b35960fe469",
   "metadata": {
    "language": "sql",
    "name": "cell44",
    "collapsed": false,
    "resultHeight": 112
   },
   "outputs": [],
   "source": "CREATE STAGE modelstage",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3686e8f4-0b05-4c67-93fc-421c10fe096a",
   "metadata": {
    "language": "python",
    "name": "cell43",
    "collapsed": false,
    "resultHeight": 354
   },
   "outputs": [],
   "source": "session.file.put('logistic_regression_model.joblib', \"@modelstage\") ",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e743d83c-ffad-4719-b1ef-324770842c14",
   "metadata": {
    "language": "python",
    "name": "cell45",
    "collapsed": false,
    "resultHeight": 0
   },
   "outputs": [],
   "source": "",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6264b1fd-c6a1-42d1-8429-4b8fcbbb0b12",
   "metadata": {
    "language": "sql",
    "name": "cell46",
    "collapsed": false,
    "resultHeight": 112
   },
   "outputs": [],
   "source": "LIST @modelstage",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "63539e2a-0139-44f2-b2cd-35a76a65f45d",
   "metadata": {
    "language": "python",
    "name": "cell42",
    "collapsed": false,
    "resultHeight": 217
   },
   "outputs": [],
   "source": "cl_metrics_df",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "803a5b2d-10a7-4ca4-bf80-6ed48fa46f1d",
   "metadata": {
    "language": "python",
    "name": "cell20",
    "collapsed": false,
    "resultHeight": 38
   },
   "outputs": [],
   "source": "import os\nimport joblib\n\n# Ensure the directory exists\nos.makedirs('models', exist_ok=True)\n\n# Save the model\njoblib.dump(classifier_log, 'models/logistic_regression_model.joblib')\nprint(\"Model saved successfully!\")\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c3f793c1-a90e-4ada-a064-94ecb808ef7d",
   "metadata": {
    "language": "python",
    "name": "cell47",
    "collapsed": false,
    "resultHeight": 38
   },
   "outputs": [],
   "source": "import os\n\nfile_path = '@modelstage/logistic_regression_model.joblib.gz'\nfile_exists = os.path.exists(file_path)\n\nif file_exists:\n    print(\"File exists.\")\nelse:\n    print(\"File does not exist.\")\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9a847cf8-2b14-4a85-aed4-31eed7dda339",
   "metadata": {
    "language": "python",
    "name": "cell48",
    "collapsed": false,
    "resultHeight": 0
   },
   "outputs": [],
   "source": "# Check if the file exists in the Snowflake stage\nstage_path = '@modelstage/logistic_regression_model.joblib.gz'\nquery = f\"SELECT COUNT(*) FROM @{stage_path}\"\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "439e292d-036b-4259-abd0-dd26d064c572",
   "metadata": {
    "language": "python",
    "name": "cell49",
    "collapsed": false,
    "resultHeight": 38
   },
   "outputs": [],
   "source": "import os\n\ncurrent_directory = os.getcwd()\nprint(\"Current directory:\", current_directory)\n",
   "execution_count": null
  }
 ]
}